{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10289415204807432219\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11332668621\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 6631158176850942352\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:06:00.0\"\n",
      ", name: \"/gpu:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11330676327\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 15407026887944723734\n",
      "physical_device_desc: \"device: 1, name: Tesla K80, pci bus id: 0000:07:00.0\"\n",
      ", name: \"/gpu:2\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11330614068\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 4996095157860593154\n",
      "physical_device_desc: \"device: 2, name: Tesla K80, pci bus id: 0000:0e:00.0\"\n",
      ", name: \"/gpu:3\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11328684032\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 16782623752990443102\n",
      "physical_device_desc: \"device: 3, name: Tesla K80, pci bus id: 0000:0f:00.0\"\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Created on Nov 24, 2017\n",
    "\n",
    "Purpose is to replicate results of Generating Adversarial Examples with Adversarial Networks, ICLR 2018.\n",
    "This script implements the training process for the GAN model.\n",
    "'''\n",
    "import sys\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "from tensorflow.python.client import device_lib\n",
    "import pickle\n",
    "print(device_lib.list_local_devices())\n",
    "import numpy as np\n",
    "#from School.STAT946.Project impimport GAN\n",
    "import keras\n",
    "import GAN\n",
    "from Losses import *\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = (500/12000)\n",
    "set_session(tf.Session(config=config))\n",
    "'''\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "# Assume that you have 12GB of GPU memory and want to allocate 500MB:\n",
    "config.gpu_options.per_process_gpu_memory_fraction=(500/12000)\n",
    "sess = tf.Session(config=config)'''\n",
    "def make_trainable(net, val):\n",
    "    net.trainable = val\n",
    "    for l in net.layers:\n",
    "        l.trainable = val\n",
    "\n",
    "def fn(correct, predicted):\n",
    "    return tf.nn.softmax_cross_entropy_with_logits(labels=correct,\n",
    "                                                       logits=predicted)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_for_n(epochs=5000,batch_size=128):\n",
    "    #from tqdm import tqdm\n",
    "    \n",
    "    for tk in range(epochs):\n",
    "        if(tk==0):\n",
    "            print(\"Entered the loop\")\n",
    "        # Make generative images\n",
    "        real_image_batch = X[np.random.randint(0,X.shape[0],size=int(batch_size/2)),:,:,:]\n",
    "        fake_image_inp = X[np.random.randint(0,X.shape[0],size=int(batch_size/2)),:,:,:]\n",
    "        fake_image_batch = np.add(fake_image_inp,G.predict(fake_image_inp))\n",
    "\n",
    "        # Train discriminator on generated images\n",
    "        X_batch = np.concatenate((real_image_batch, fake_image_batch))\n",
    "        y1 = np.zeros([batch_size,1])\n",
    "        y1[0:int(batch_size/2),] = 1\n",
    "        \n",
    "        make_trainable(D,True)\n",
    "        D.train_on_batch(X_batch,y1)\n",
    "        #d_loss  = D.train_on_batch(X_batch,y1)\n",
    "        #losses[\"d\"][e]=d_loss\n",
    "\n",
    "        #train Generator-Discriminator stack on input noise to non-generated output class\n",
    "        sample_int=np.random.randint(0,X.shape[0],size=int(batch_size))\n",
    "        fake_image_inp = X[sample_int,:,:,:]\n",
    "        y_discrim = np.ones([batch_size,1])\n",
    "        y_class=y[sample_int]\n",
    "        y_hinge=np.zeros([batch_size,28,28,1])\n",
    "        \n",
    "        make_trainable(D,False)\n",
    "        scalarloss=GAN.train_on_batch(fake_image_inp, [y_discrim,y_class,y_hinge])\n",
    "        #g_loss = GAN.train_on_batch(noise_tr, y2 )\n",
    "        if(tk%500==0):\n",
    "            print(\"Epoch number:\",tk,\"; Loss\",scalarloss)\n",
    "         #losses[\"g\"][e]=g_loss\n",
    "    #GAN.save('GAN_CPristine100')\n",
    "    #G.save('G_CPristine100')\n",
    "    #D.save('D_CPristine100')\n",
    "    #f.save('f_CPristine100')\n",
    "    \n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phew\n",
      "I'm here 111\n",
      "Tensor(\"model_1_target:0\", shape=(?, ?, ?, ?), dtype=float32)\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 28, 28, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 28, 28, 1)     85757       input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "add_5 (Add)                      (None, 28, 28, 1)     0           input_3[0][0]                    \n",
      "                                                                   model_1[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "model_2 (Model)                  (None, 1)             10717       add_5[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)        (None, 10)            893258      add_5[0][0]                      \n",
      "====================================================================================================\n",
      "Total params: 989,732\n",
      "Trainable params: 96,474\n",
      "Non-trainable params: 893,258\n",
      "____________________________________________________________________________________________________\n",
      "=||==||==||==||==||==||==||=\n",
      "=||==||==||==||==||==||==||=\n",
      "Model F\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 21, 21, 64)        4160      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 21, 21, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 128)       295040    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 12, 12, 128)       409728    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                184330    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 893,258\n",
      "Trainable params: 0\n",
      "Non-trainable params: 893,258\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "GAN, G, D, f= GAN.Define_GAN([28,28,1], 100, 10000,'B')\n",
    "print(\"=||=\"*7)\n",
    "print(\"=||=\"*7)\n",
    "#f.summary()\n",
    "(X,y),(_,_)=mnist.load_data()\n",
    "X= np.divide(X,255)\n",
    "X=X.reshape(X.shape[0],28,28,1)\n",
    "y=to_categorical(y, num_classes=10)\n",
    "make_trainable(f,False)\n",
    "print('Model F\\n')\n",
    "f.summary()\n",
    "#make_trainable(f2,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entered the loop\n",
      "Epoch number: 0 ; Loss [18501.371, 0.57678562, 0.50421798, 1.8450373, 0.0078125, 0.671875, 0.75310874]\n",
      "Epoch number: 500 ; Loss [95.327805, 0.19876346, 0.30905026, 0.0064224014, 1.0, 0.5, 0.99999958]\n",
      "Epoch number: 1000 ; Loss [28.021957, 0.19256291, 0.27769381, 6.0014509e-06, 1.0, 0.4609375, 0.99999958]\n",
      "Epoch number: 1500 ; Loss [46.326061, 0.19508506, 0.46130976, 0.0, 1.0, 0.6796875, 0.99999958]\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "train_for_n(epochs=2000,batch_size=128)\n",
    "GAN.save_weights('WhiteBox/B_Wbox_Ganwt3k')\n",
    "G.save_weights('WhiteBox/B_Wbox_Gwt3k')\n",
    "D.save_weights('WhiteBox/B_Wbox_Dwt3k')\n",
    "f.save_weights('WhiteBox/B_Wbox_fwt3k')\n",
    "print('Done')\n",
    "#GAN.save('GAN_BPristine15000')\n",
    "#G.save('G_BPristine15000')\n",
    "#D.save('D_BPristine15000')\n",
    "#f.save('f_BPristine15000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#This is the compile function for C. To be called \"After freezing the weights\"\n",
    "#sgd= SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#f2.compile(loss=fn,optimizer=sgd,metrics=['accuracy'])\n",
    "#f.summary()\n",
    "#make_trainable(f2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"GAN.load_weights('WhiteBox/B_Wbox_Ganwt2k')\\nG.load_weights('WhiteBox/B_Wbox_Gwt2k')\\nD.load_weights('WhiteBox/B_Wbox_Dwt2k')\\nf.load_weights('WhiteBox/B_Wbox_fwt2k')\\nmake_trainable(f, False)\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GAN, G, D, f= GAN.Define_GAN([28,28,1], 1, 10000,'B')\n",
    "'''GAN.load_weights('WhiteBox/B_Wbox_Ganwt2k')\n",
    "G.load_weights('WhiteBox/B_Wbox_Gwt2k')\n",
    "D.load_weights('WhiteBox/B_Wbox_Dwt2k')\n",
    "f.load_weights('WhiteBox/B_Wbox_fwt2k')\n",
    "make_trainable(f, False)'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
